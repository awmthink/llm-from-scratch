{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/yangyansheng/.cache/huggingface/modules/datasets_modules/datasets/code_search_net/8f2524e6b62f65af5f5d65c53715c654db7b08dc93e0b7bcce2ab2f286a75be1 (last modified on Mon Dec 18 10:40:29 2023) since it couldn't be found locally at code_search_net., or remotely on the Hugging Face Hub.\n",
      "Found cached dataset code_search_net (/home/yangyansheng/.cache/huggingface/datasets/code_search_net/python/1.0.0/8f2524e6b62f65af5f5d65c53715c654db7b08dc93e0b7bcce2ab2f286a75be1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37628e644a54824832c4c245654af4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 457K rows\n",
    "raw_datasets = load_dataset(\"code_search_net\", \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repository_name': Value(dtype='string', id=None),\n",
       " 'func_path_in_repository': Value(dtype='string', id=None),\n",
       " 'func_name': Value(dtype='string', id=None),\n",
       " 'whole_func_string': Value(dtype='string', id=None),\n",
       " 'language': Value(dtype='string', id=None),\n",
       " 'func_code_string': Value(dtype='string', id=None),\n",
       " 'func_code_tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'func_documentation_string': Value(dtype='string', id=None),\n",
       " 'func_documentation_tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'split_name': Value(dtype='string', id=None),\n",
       " 'func_code_url': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def _get_class_handlers(cls, signal_name, instance):\n",
      "        \"\"\"Returns the handlers registered at class level.\n",
      "        \"\"\"\n",
      "        handlers = cls._signal_handlers_sorted[signal_name]\n",
      "        return [getattr(instance, hname) for hname in handlers]\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][1234][\"whole_func_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    return (\n",
    "        raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
    "        for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "train_corpus = get_training_corpus()\n",
    "\n",
    "tokenizer = old_tokenizer.train_new_from_iterator(train_corpus, 52000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./python_code_tokenizer/tokenizer_config.json',\n",
       " './python_code_tokenizer/special_tokens_map.json',\n",
       " './python_code_tokenizer/vocab.json',\n",
       " './python_code_tokenizer/merges.txt',\n",
       " './python_code_tokenizer/added_tokens.json',\n",
       " './python_code_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./python_code_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "\n",
    "from transformers import AutoTokenizer, LlamaTokenizer\n",
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "import sentencepiece as spm\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389841"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_sp_model = spm.SentencePieceProcessor()\n",
    "chinese_sp_model.Load(\"./medical_sp.model\")\n",
    "chinese_spm = sp_pb2_model.ModelProto()\n",
    "chinese_spm.ParseFromString(chinese_sp_model.serialized_model_proto())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1658691"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"/home/yangyansheng/workspace/models/internlm-chat-7b\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "llama_spm = sp_pb2_model.ModelProto()\n",
    "llama_spm.ParseFromString(llama_tokenizer.sp_model.serialized_model_proto())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0xFD> 0.0\n",
      "<0xFE> 0.0\n",
      "<0xFF> 0.0\n",
      "' -1635.0\n",
      "b -1.0\n",
      "e -2.0\n",
      "‚ñÅ -1298.0\n",
      "t -4.0\n",
      "a -5.0\n",
      "n -6.0\n",
      "i -7.0\n",
      "r -8.0\n",
      "o -9.0\n",
      "s -10.0\n",
      "l -11.0\n",
      "c -12.0\n",
      "\\ -2473.0\n",
      "d -14.0\n",
      "x -15.0\n",
      "u -16.0\n"
     ]
    }
   ],
   "source": [
    "start = 256\n",
    "pieces = llama_spm.pieces[start : start + 20]\n",
    "\n",
    "for piece in pieces:\n",
    "    print(piece.piece, piece.score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
